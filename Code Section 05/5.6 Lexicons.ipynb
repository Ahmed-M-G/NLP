{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('plan.n.01'),\n",
       " Synset('program.n.02'),\n",
       " Synset('broadcast.n.02'),\n",
       " Synset('platform.n.02'),\n",
       " Synset('program.n.05'),\n",
       " Synset('course_of_study.n.01'),\n",
       " Synset('program.n.07'),\n",
       " Synset('program.n.08'),\n",
       " Synset('program.v.01'),\n",
       " Synset('program.v.02')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "syns = wordnet.synsets(\"program\")\n",
    "syns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('plan.n.01')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan.n.01'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[0].lemmas()[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a series of steps to be carried out or goals to be accomplished\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('school.n.01'),\n",
       " Synset('school.n.02'),\n",
       " Synset('school.n.03'),\n",
       " Synset('school.n.04'),\n",
       " Synset('school.n.05'),\n",
       " Synset('school.n.06'),\n",
       " Synset('school.n.07'),\n",
       " Synset('school.v.01'),\n",
       " Synset('educate.v.03'),\n",
       " Synset('school.v.03')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('like.n.01'),\n",
       " Synset('like.n.02'),\n",
       " Synset('wish.v.02'),\n",
       " Synset('like.v.02'),\n",
       " Synset('like.v.03'),\n",
       " Synset('like.v.04'),\n",
       " Synset('like.v.05'),\n",
       " Synset('like.a.01'),\n",
       " Synset('like.a.02'),\n",
       " Synset('alike.a.01'),\n",
       " Synset('comparable.s.02')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metal supports for logs in a fireplace'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('andiron.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definition : feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
      "-----------------\n",
      "examples : []\n",
      "=========================================\n",
      "definition : an informal term for a youth or man\n",
      "-----------------\n",
      "examples : ['a nice guy', \"the guy's only doing it for some doll\"]\n",
      "=========================================\n",
      "definition : a spiteful woman gossip\n",
      "-----------------\n",
      "examples : ['what a cat she is!']\n",
      "=========================================\n",
      "definition : the leaves of the shrub Catha edulis which are chewed like tobacco or used to make tea; has the effect of a euphoric stimulant\n",
      "-----------------\n",
      "examples : ['in Yemen kat is used daily by 85% of adults']\n",
      "=========================================\n",
      "definition : a whip with nine knotted cords\n",
      "-----------------\n",
      "examples : ['British sailors feared the cat']\n",
      "=========================================\n",
      "definition : a large tracked vehicle that is propelled by two endless metal belts; frequently used for moving earth in construction and farm work\n",
      "-----------------\n",
      "examples : []\n",
      "=========================================\n",
      "definition : any of several large cats typically able to roar and living in the wild\n",
      "-----------------\n",
      "examples : []\n",
      "=========================================\n",
      "definition : a method of examining body organs by scanning them with X rays and using a computer to construct a series of cross-sectional scans along a single axis\n",
      "-----------------\n",
      "examples : []\n",
      "=========================================\n",
      "definition : beat with a cat-o'-nine-tails\n",
      "-----------------\n",
      "examples : []\n",
      "=========================================\n",
      "definition : eject the contents of the stomach through the mouth\n",
      "-----------------\n",
      "examples : ['After drinking too much, the students vomited', 'He purged continuously', 'The patient regurgitated the food we gave him last night']\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "word = 'cat'\n",
    "# word = 'egypt'\n",
    "# word = 'john'\n",
    "# word = 'hitler'\n",
    "# word = 'earth'\n",
    "\n",
    "for i in wn.synsets(word) : \n",
    "    print(f'definition : {i.definition()}')\n",
    "    print('-----------------')\n",
    "    print(f'examples : {i.examples()}')\n",
    "    print('=========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unspoilt', 'estimable', 'well', 'secure', 'near', 'dependable', 'commodity', 'in_force', 'full', 'adept', 'honorable', 'salutary', 'ripe', 'skillful', 'thoroughly', 'sound', 'dear', 'proficient', 'good', 'goodness', 'trade_good', 'effective', 'skilful', 'soundly', 'beneficial', 'practiced', 'in_effect', 'undecomposed', 'respectable', 'safe', 'just', 'unspoiled', 'right', 'expert', 'upright', 'serious', 'honest'}\n",
      "{'badness', 'evil', 'ill', 'bad', 'evilness'}\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(set(synonyms))\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : I\n",
      "\n",
      "synonyms : {'unity', '1', 'single', 'atomic_number_53', 'i', 'ace', 'ane', 'I', 'one', 'iodin', 'iodine'}\n",
      "===========================================\n",
      "word : need\n",
      "\n",
      "synonyms : {'take', 'demand', 'involve', 'motive', 'require', 'necessitate', 'pauperism', 'penury', 'pauperization', 'need', 'ask', 'call_for', 'want', 'indigence', 'motivation', 'postulate'}\n",
      "===========================================\n",
      "word : to\n",
      "===========================================\n",
      "word : go\n",
      "\n",
      "synonyms : {'plump', 'depart', 'run_short', 'tour', 'XTC', 'hold_out', 'disco_biscuit', 'hold_up', 'whirl', \"cash_in_one's_chips\", 'break_down', 'work', 'run_low', 'function', 'get', 'operate', 'buy_the_farm', 'proceed', 'conk_out', 'pop_off', 'cristal', 'pass', 'belong', 'spell', 'fit', 'give_out', 'X', 'survive', 'decease', 'kick_the_bucket', 'live', 'sound', 'die', 'exit', 'rifle', 'croak', 'ecstasy', 'blend', 'Adam', 'expire', 'give_way', 'fling', 'go_bad', 'break', 'move', 'become', 'drop_dead', 'go', 'go_game', 'lead', 'endure', 'get_going', 'snuff_it', 'pass_away', 'travel', 'last', 'crack', 'fail', 'conk', 'give-up_the_ghost', 'live_on', 'perish', 'start', 'offer', 'run', 'hug_drug', 'choke', 'blend_in', 'extend', 'turn', 'locomote', 'go_away'}\n",
      "\n",
      "antonyms : {'malfunction', 'come', 'no-go', 'be_born', 'stop', 'stay_in_place'}\n",
      "\n",
      "===========================================\n",
      "word : right\n",
      "\n",
      "synonyms : {'proper', 'mighty', 'properly', 'decently', 'veracious', 'right_hand', 'powerful', 'correct', 'right_field', 'redress', 'rectify', 'the_right_way', 'ripe', 'compensate', 'decent', 'good', 'mightily', 'rightfield', 'right_wing', 'aright', 'right', 'justly', 'correctly', 'in_good_order', 'flop', 'rightfulness', 'right-hand', 'right_on'}\n",
      "===========================================\n",
      "word : now\n",
      "\n",
      "synonyms : {'directly', 'straight_off', 'at_once', 'today', 'instantly', 'now', 'right_away', 'at_present', 'nowadays', 'forthwith', 'straightaway', 'like_a_shot', 'immediately'}\n",
      "===========================================\n",
      "word : to\n",
      "===========================================\n",
      "word : my\n",
      "===========================================\n",
      "word : friend\n",
      "\n",
      "synonyms : {'booster', 'protagonist', 'Friend', 'ally', 'admirer', 'friend', 'acquaintance', 'supporter', 'Quaker', 'champion'}\n",
      "===========================================\n",
      "word : Hasan\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "text = 'I need to go right now to my friend Hasan'\n",
    "\n",
    "for word in word_tokenize(text) : \n",
    "    synonyms = []\n",
    "    antonyms = []\n",
    "    \n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "            if l.antonyms():\n",
    "                antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "    print(f'word : {word}')\n",
    "    if len(synonyms) >1 :print(f'\\nsynonyms : {set(synonyms)}')\n",
    "    if l.antonyms(): print(f'\\nantonyms : {set(antonyms)}\\n')\n",
    "    print('===========================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syn (water.n.01) and (air.n.01) with similarity 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# word1 = 'green'\n",
    "# word2 = 'blue'\n",
    "\n",
    "# word1 = 'moon'\n",
    "# word2 = 'sun'\n",
    "\n",
    "word1 = 'water'\n",
    "word2 = 'air'\n",
    "\n",
    "# word1 = 'france'\n",
    "# word2 = 'paris'\n",
    "\n",
    "# word1 = 'lion'\n",
    "# word2 = 'shoes'\n",
    "\n",
    "\n",
    "w1 = wordnet.synset(wordnet.synsets(word1)[0].name())\n",
    "w2 = wordnet.synset(wordnet.synsets(word2)[0].name())\n",
    "print(f'Syn ({wordnet.synsets(word1)[0].name()}) and ({wordnet.synsets(word2)[0].name()}) with similarity {w1.wup_similarity(w2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syn (iodine.n.01) and (iodine.n.01) with similarity 1.0\n",
      "----------------------------------------\n",
      "Syn (iodine.n.01) and (travel.v.01) with similarity None\n",
      "----------------------------------------\n",
      "Syn (iodine.n.01) and (school.n.01) with similarity 0.46153846153846156\n",
      "----------------------------------------\n",
      "Syn (iodine.n.01) and (day.n.01) with similarity 0.4\n",
      "----------------------------------------\n",
      "Syn (iodine.n.01) and (talk.n.01) with similarity 0.3333333333333333\n",
      "----------------------------------------\n",
      "Syn (iodine.n.01) and (teacher.n.01) with similarity 0.2857142857142857\n",
      "----------------------------------------\n",
      "Syn (travel.v.01) and (iodine.n.01) with similarity 0.25\n",
      "----------------------------------------\n",
      "Syn (travel.v.01) and (travel.v.01) with similarity 1.0\n",
      "----------------------------------------\n",
      "Syn (travel.v.01) and (school.n.01) with similarity 0.18181818181818182\n",
      "----------------------------------------\n",
      "Syn (travel.v.01) and (day.n.01) with similarity 0.25\n",
      "----------------------------------------\n",
      "Syn (travel.v.01) and (talk.n.01) with similarity 0.2\n",
      "----------------------------------------\n",
      "Syn (travel.v.01) and (teacher.n.01) with similarity 0.16666666666666666\n",
      "----------------------------------------\n",
      "Syn (school.n.01) and (iodine.n.01) with similarity 0.46153846153846156\n",
      "----------------------------------------\n",
      "Syn (school.n.01) and (travel.v.01) with similarity None\n",
      "----------------------------------------\n",
      "Syn (school.n.01) and (school.n.01) with similarity 1.0\n",
      "----------------------------------------\n",
      "Syn (school.n.01) and (day.n.01) with similarity 0.3076923076923077\n",
      "----------------------------------------\n",
      "Syn (school.n.01) and (talk.n.01) with similarity 0.26666666666666666\n",
      "----------------------------------------\n",
      "Syn (school.n.01) and (teacher.n.01) with similarity 0.125\n",
      "----------------------------------------\n",
      "Syn (day.n.01) and (iodine.n.01) with similarity 0.4\n",
      "----------------------------------------\n",
      "Syn (day.n.01) and (travel.v.01) with similarity None\n",
      "----------------------------------------\n",
      "Syn (day.n.01) and (school.n.01) with similarity 0.3076923076923077\n",
      "----------------------------------------\n",
      "Syn (day.n.01) and (day.n.01) with similarity 1.0\n",
      "----------------------------------------\n",
      "Syn (day.n.01) and (talk.n.01) with similarity 0.3333333333333333\n",
      "----------------------------------------\n",
      "Syn (day.n.01) and (teacher.n.01) with similarity 0.15384615384615385\n",
      "----------------------------------------\n",
      "Syn (talk.n.01) and (iodine.n.01) with similarity 0.3333333333333333\n",
      "----------------------------------------\n",
      "Syn (talk.n.01) and (travel.v.01) with similarity None\n",
      "----------------------------------------\n",
      "Syn (talk.n.01) and (school.n.01) with similarity 0.26666666666666666\n",
      "----------------------------------------\n",
      "Syn (talk.n.01) and (day.n.01) with similarity 0.3333333333333333\n",
      "----------------------------------------\n",
      "Syn (talk.n.01) and (talk.n.01) with similarity 1.0\n",
      "----------------------------------------\n",
      "Syn (talk.n.01) and (teacher.n.01) with similarity 0.13333333333333333\n",
      "----------------------------------------\n",
      "Syn (teacher.n.01) and (iodine.n.01) with similarity 0.2857142857142857\n",
      "----------------------------------------\n",
      "Syn (teacher.n.01) and (travel.v.01) with similarity None\n",
      "----------------------------------------\n",
      "Syn (teacher.n.01) and (school.n.01) with similarity 0.125\n",
      "----------------------------------------\n",
      "Syn (teacher.n.01) and (day.n.01) with similarity 0.15384615384615385\n",
      "----------------------------------------\n",
      "Syn (teacher.n.01) and (talk.n.01) with similarity 0.13333333333333333\n",
      "----------------------------------------\n",
      "Syn (teacher.n.01) and (teacher.n.01) with similarity 1.0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text = 'I went to the school that day to talk to the teacher'\n",
    "\n",
    "for word1 in word_tokenize(text) : \n",
    "    for word2 in word_tokenize(text) :\n",
    "        if len(wordnet.synsets(word1))>0 and len(wordnet.synsets(word2))>0  : \n",
    "            w1 = wordnet.synset(wordnet.synsets(word1)[0].name())\n",
    "            w2 = wordnet.synset(wordnet.synsets(word2)[0].name())\n",
    "            print(f'Syn ({wordnet.synsets(word1)[0].name()}) and ({wordnet.synsets(word2)[0].name()}) with similarity {w1.wup_similarity(w2)}')\n",
    "            print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
